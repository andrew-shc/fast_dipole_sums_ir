general {
    base_exp_dir = ./exp/CASE_NAME/
    recording = [
        ./,
        ./models,
        ./util
    ]
}

dataset {
    data_dir = ./public_data/CASE_NAME/
    render_cameras_name = cameras_sphere.npz
    object_cameras_name = cameras_sphere.npz
}

train {
    learning_rate_pc = 1e-2
    learning_rate_color = 3e-3
    learning_rate_nerf = 3e-4
    learning_rate_alpha = 0.05
    end_iter = 20000

    batch_size = 4096
    validate_resolution_level = 2
    validate_mesh_resolution = 512
    warm_up_end = 100
    anneal_end = 0
    use_white_bkgd = False

    save_freq = 10000
    val_freq = 1000
    val_mesh_freq = 5000
    report_freq = 100

    mask_weight = 0.0
    entropy_weight = 1e-3
    reg_weight_w = 1e-4
    reg_weight_n = 0.1

    isect_sampling = True

    gradient_accumulation = 1

    grow_point = True
    grow_point_start = 3000
    grow_point_end = 7000
    grow_point_step = 500
    grow_point_num_images = 16
    grow_point_thresh = 0.01
}

model {
    nerf {
        D = 8,
        d_in = 4,
        d_in_view = 3,
        W = 256,
        multires = 10,
        multires_view = 4,
        output_ch = 4,
        skips=[4],
        use_viewdirs=True
    }

    point_cloud {
        ply_path = ./point_cloud_data/CASE_NAME/dense/points.ply,
        num_points = 70000,
        from_colmap = True,
        num_sh_features = 32,
        beta = 2.0,
        bounding_sphere = 1.0,
        trained_model = False,
        optimize_normals = True,
        use_color_nn = True,
        activation = erf,
        is_dtu = True
    }

    rendering_network {
        d_feature = 32
        mode = idr
        d_in = 9
        d_out = 3
        d_hidden = 256
        n_layers = 4
        weight_norm = True
        multires_view = 3
        use_dir_enc = True
        squeeze_out = True
    }

	point_sampler {
	    n_sdf_pts = 1024
        n_fg_samples = 24
	    n_surf_samples = 48
	    n_bg_samples = 8
	    n_outside = 32
	}
}
